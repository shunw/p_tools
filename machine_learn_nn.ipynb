{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron -> Multiple Perceptrons (MLP)\n",
    "\n",
    "- perceptron is one of the simplest ANN (artificial neural network); MLP is the resulting ANN. \n",
    "\n",
    "- similar to Stochastic Gradient Descent\n",
    "\n",
    "- don't output a class probability, rather, they make a predictions based on a hard threshold. \n",
    "\n",
    "`from sklearn.linear_model import Perceptron`\n",
    "\n",
    "- MLP (with two hidden layers)\n",
    "\n",
    "    - scale first\n",
    "\n",
    "    - Sequential API\n",
    "        ```\n",
    "        model = keras.models.Sequential([\n",
    "            keras.layers.Flatten(input_shape = [28, 28]),\n",
    "            keras.layers.Dense(300, activation = 'relu'), \n",
    "            keras.layers.Dense(100, activation = 'relu'), \n",
    "            keras.layers.Dense(10, activation = 'softmax')\n",
    "        ])\n",
    "        ```\n",
    "    - compile the model\n",
    "\n",
    "        - loss: for sparse labels (0-9 exclusive) => sparse_categorcial_crossentropy; for one-hot vector => categorial_crossentropy; binary output => binary_crossentropy\n",
    "\n",
    "        - optimizer: sgd => Stochastic Gradient Descent <= need to tune the learning rate; \n",
    "\n",
    "            ```\n",
    "            model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])\n",
    "            ```\n",
    "\n",
    "    - train data\n",
    "\n",
    "        ```\n",
    "        history = model.fit(X_train, y_train, epochs = 30, validation_data = (X_valid, y_valid))\n",
    "        history.params\n",
    "        history.epochs\n",
    "        history.history \n",
    "\n",
    "        pd.DataFrame(history.history).plot(figsize = (8, 5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0, 1)\n",
    "        plt.show()\n",
    "        ```\n",
    "    - tune\n",
    "\n",
    "        - learning rate\n",
    "\n",
    "        - other optimizer (also need to tune learning rate)\n",
    "\n",
    "        - mode hyperparameter (# layers; # neurons; activation function; batch size)\n",
    "\n",
    "    - test\n",
    "\n",
    "        `model.evaluate(X_test, y_test)`\n",
    "\n",
    "    - some layer info\n",
    "        ```\n",
    "        h = model.layers[1]\n",
    "        h.name\n",
    "        model.get_layer('dense') is h => True\n",
    "        weights, biases = h.get_weights()\n",
    "        ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network (DNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow\n",
    "\n",
    "[playground](https://playground.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load Tensorflow\n",
    "\n",
    "[save&load](https://www.tensorflow.org/tutorials/keras/save_and_load)"
   ]
  }
 ]
}