{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36564bitff28b0bc308b43728a982148efad7fb6",
   "display_name": "Python 3.6.5 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Way Analysis of ANOVA\n",
    "\n",
    "Decide if different group have different mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept: \n",
    "\n",
    "- total sum of squares: \n",
    "    \n",
    "    - SStotal = sum((indivival - overall mean) ** 2)\n",
    "\n",
    "        - Stotal**2 = SStotal / (n - 1) \n",
    "\n",
    "        - n is the degree of freedom\n",
    "\n",
    "    - SStotal = SSexpl + SSunexpl\n",
    "\n",
    "    - SSbtwn == SSexpl = sum((group mean - overall mean) ** 2)\n",
    "\n",
    "        - Sb**2 = MSb = SSbtwn / (k - 1)\n",
    "\n",
    "        - k is the group qty\n",
    "\n",
    "        - explained, singal\n",
    "    \n",
    "    - SSwithin == SSunexpl = sum((indivival - group mean) ** 2)\n",
    "\n",
    "        - Sw**2 = MSw = SSwithin / (n-k)\n",
    "\n",
    "        - n is the total observation\n",
    "\n",
    "        - unexplained, noise\n",
    "\n",
    "- think about several questions, and try to answer it: \n",
    "\n",
    "    - why not everyone have same weight lost? <- this is example shown in the video. \n",
    "        \n",
    "        - diets may different -> explained by diet \"X\" <- BETWEEN\n",
    "\n",
    "        - people may different -> unexplained by diet \"X\" <- WITHIN\n",
    "\n",
    "    - in the actual life, this could be: \n",
    "\n",
    "        - why different engine have different shift? <- unexplained by ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H0: All means are same (for each group)\n",
    "\n",
    "H1: At least one diff. \n",
    "\n",
    "Assumption: \n",
    "\n",
    "- simple random sample\n",
    "\n",
    "- independent observations\n",
    "\n",
    "- independent groups\n",
    "\n",
    "- SD(standard deviation of each group) are same\n",
    "\n",
    "- each group has large sample size. (> 20). OR  groups are proximately normal\n",
    "\n",
    "Expect: \n",
    "\n",
    "- If Ha true => MSb > MSw => F = MSb/ MSw > 1\n",
    "\n",
    "- If H0 true => MSb == MSw => F = MSb/ MSw == 1\n",
    "\n",
    "Wendy's comment (不确定是否正确): \n",
    "\n",
    "- about the dfn/ dfd\n",
    "\n",
    "    - MSb and MSw其实都是从计算sample的variation中转换出来的\n",
    "    \n",
    "    - [sample var cal](https://en.wikipedia.org/wiki/Variance)\n",
    "\n",
    "    - MSw 计算的是各个组中的 sample 的 var; sample var需要 除以 n -1 => 每个组 ni -1 => 需要计算各个组 (ni - 1) * k => n - k\n",
    "\n",
    "    - MSb 因为是between 组=> n -1 为 k -1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the assumption does not meet, like if we have small n, non-normality or need to compare median instead of median\n",
    "\n",
    "- non-param -> KRUSKAL WALLIS\n",
    "\n",
    "    - `scipy.stats.kruskal(data_a, data_b, data_c, data_d)`\n",
    "\n",
    "    - could double check the result, similar as one-way AVONA\n",
    "\n",
    "- bootstrap/ re-sample approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MSw is 5.303\n6.117525665200089\nP-value = P(Fstat >= 6.1 if H0 is true) = 0.001\nSo, accept Ha that at least one differs\n6.117525665200085 0.001127857509636891\n"
    }
   ],
   "source": [
    "# to understand anova\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "df = pd.read_csv('DietWeigthLoss.csv')\n",
    "df['WeightLoss'] = df['WeightLoss\\tDiet'].apply(lambda x: float(x.split()[0]))\n",
    "df['Diet']= df['WeightLoss\\tDiet'].apply(lambda x: x.split()[1])\n",
    "df=df[['WeightLoss', 'Diet']]\n",
    "\n",
    "wtl = 'WeightLoss'\n",
    "data_a = df.loc[df['Diet'] == 'A', wtl]\n",
    "data_b = df.loc[df['Diet'] == 'B', wtl]\n",
    "data_c = df.loc[df['Diet'] == 'C', wtl]\n",
    "data_d = df.loc[df['Diet'] == 'D', wtl]\n",
    "\n",
    "total_data_ls = [data_a, data_b, data_c, data_d]\n",
    "grp_mean_ls = []\n",
    "grp_std2_ls = []\n",
    "for grp in total_data_ls: \n",
    "    grp_mean_ls.append(grp.mean())\n",
    "    grp_std2_ls.append(grp.std() ** 2)\n",
    "\n",
    "total_mean = df[wtl].mean()\n",
    "\n",
    "MSb = 0 # variation between group/ explainable/ Mean Square Between\n",
    "for ind, grpm in enumerate(grp_mean_ls): \n",
    "    data_n = len(total_data_ls[ind]) # data number within a group\n",
    "    MSb += (grpm - total_mean) ** 2 * data_n\n",
    "\n",
    "grp_num = len(total_data_ls)\n",
    "total_data_num = df.shape[0]\n",
    "\n",
    "MSb = MSb / (grp_num - 1)\n",
    "\n",
    "MSw = 0 # variation within group/ unexplainable/ Mean Square Within\n",
    "for ind, data in enumerate(total_data_ls): \n",
    "    temp = data.apply(lambda x: (x - grp_mean_ls[ind])** 2)\n",
    "    MSw += temp.sum() \n",
    "\n",
    "MSw_1 = 0\n",
    "for ind, std2 in enumerate(grp_std2_ls): \n",
    "    MSw_1 += (len(total_data_ls[ind]) - 1) * std2\n",
    "MSw = MSw / (total_data_num - grp_num)\n",
    "print ('MSw is {:.3f}'.format(MSw))\n",
    "Fstat = MSb/ MSw\n",
    "print (Fstat)\n",
    "dfn = grp_num - 1\n",
    "dfd = total_data_num - grp_num\n",
    "Pr = 1 - stats.f.cdf(Fstat, dfn, dfd)\n",
    "\n",
    "print ('P-value = P(Fstat >= 6.1 if H0 is true) = {:.3f}'.format(Pr))\n",
    "print ('So, accept Ha that at least one differs')\n",
    "\n",
    "stat, pvalue = stats.f_oneway(data_a, data_b, data_c, data_d)\n",
    "print (stat, pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Testing\n",
    "\n",
    "Decide which mean is differnt among the multiple groups\n",
    "\n",
    "Theory: The probability of making at least one Type I Error (alpha) increases with every additional test we conduct\n",
    "\n",
    "Which is The more tests we do simultaneously, the greater chance of making a type I error!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparision \n",
    "\n",
    "- All Pairwise Comparision: \n",
    "\n",
    "    - compare: AB, AC, AD, BC, BC, CD\n",
    "\n",
    "    - Run independent 2-sample t-test\n",
    "\n",
    "    - for each test, if we use alpha = .05. => P(type I error) = .05; P(not type I error) = .95\n",
    "\n",
    "    - for over all tests, P(at least one type I) = 1- P(no type I errors) = 1-(p(no type I error btw A, B) x ... x p(no type I error btw C, D)) = 1- .95 ** 6 = .265 \n",
    "\n",
    "- TukeyHSD => to check which mean are stats different over others. \n",
    "\n",
    "    ```\n",
    "    from statsmodels.stats.multicomp import pairwise_tukeyhsd, MultiComparison\n",
    "\n",
    "    mc = MultiComparison(df[wtl], df['Diet'])\n",
    "\n",
    "    result = mc.tukeyhsd()\n",
    "    ```\n",
    "\n",
    "    - below Bonferroni is just check by hand\n",
    "\n",
    "- Bonferroni Correction/ Approach\n",
    "\n",
    "    - alph* = .05/ # comp = .05/ 6 = .00833 => confidence is 99.167% for each of these compare group\n",
    "\n",
    "    - P(at least one type I) = .00833\n",
    "\n",
    "    - P(at least one type I /over all) = 1-.99167**6 =4.9%\n",
    "\n",
    "    - t_val (2.735) <= stats.t.ppf(1-.05/6/2, 15x4 - 4) <= 6 is the group number; 2 is the two tail; 15 * 4 - 4 is the df\n",
    "\n",
    "    - 5.303 is the MSw get from the ANOVA; 15 is the sample number within a group\n",
    "\n",
    "    - ![avonva_pair_compare](conf_inter_anova.png)\n",
    "\n",
    "- Conclusion\n",
    "\n",
    "    - ![avonva_pair_compare](anova_conclude_btw_grps.png)\n",
    "    \n",
    "    - C is significantly over A and B. D is in the middle because D is not significantly over A and B, and also C is not significantly over D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[-2.03,  2.57],\n       [-5.23, -0.63],\n       [-3.66,  0.94],\n       [-5.51, -0.91],\n       [-3.93,  0.67],\n       [-0.73,  3.87]])"
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "pairwise_cmp = []\n",
    "\n",
    "t_val_SE = stats.t.ppf(1 - .05/ 6/ 2, 15 * 4 - 4) * ((5.303 * 2/ 15) ** .5)\n",
    "\n",
    "for i, d in enumerate(total_data_ls): \n",
    "    if i == grp_num - 1: break \n",
    "    for j in range(i + 1, grp_num): \n",
    "        lower = d.mean() - total_data_ls[j].mean() - t_val_SE\n",
    "        upper = d.mean() - total_data_ls[j].mean() + t_val_SE\n",
    "        pairwise_cmp.append([lower, upper])\n",
    "\n",
    "\n",
    "print (np.around(pairwise_cmp, 2))\n",
    "\n",
    "print ('there is a stats significant different betweem Group A and Group C; Group B and Group C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Multiple Comparison of Means - Tukey HSD,FWER=0.05\n============================================\ngroup1 group2 meandiff  lower  upper  reject\n--------------------------------------------\n  A      B    -0.2733    -2.5  1.9534 False \n  A      C     2.9333   0.7066  5.16   True \n  A      D      1.36   -0.8667 3.5867 False \n  B      C     3.2067    0.98  5.4334  True \n  B      D     1.6333  -0.5934  3.86  False \n  C      D    -1.5733    -3.8  0.6534 False \n--------------------------------------------\n['A' 'B' 'C' 'D']\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "KruskalResult(statistic=15.902089126163188, pvalue=0.0011876192544820314)"
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd, MultiComparison\n",
    "\n",
    "mc = MultiComparison(df[wtl], df['Diet'])\n",
    "result = mc.tukeyhsd()\n",
    "\n",
    "print (result)\n",
    "print (mc.groupsunique)\n",
    "\n",
    "stats.kruskal(data_a, data_b, data_c, data_d)"
   ]
  }
 ]
}