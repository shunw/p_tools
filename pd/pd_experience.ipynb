{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36564bitff28b0bc308b43728a982148efad7fb6",
   "display_name": "Python 3.6.5 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal w/ Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort By\n",
    "\n",
    "`result = df.sort_values(['A', 'B'], ascending=[1, 0])`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop duplicates\n",
    "\n",
    "`df_short = df_short.drop_duplicates([col1, col2], keep='last')`\n",
    "\n",
    "### drop w/ condition\n",
    "\n",
    "`df.drop(df[df[col] == value], inplace = True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diff by group \n",
    "`df[new_col] = df.groupby('groupby_col')['to_diff_col'].diff()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate by group \n",
    "\n",
    "`df.groupby(['col1', 'col2']).sum()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create duplicate by value\n",
    "\n",
    "`df = df.loc[df.index.repeat(df[col_name])]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find String\n",
    "\n",
    "`df[df[col_name].str.contains(\"sub_string1|sub_string2\")]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace str w/ re.findall \n",
    "\n",
    "`df[col].replace('(http.*?)\\s', 'URL', regex = True, inplace = True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower Case\n",
    "\n",
    "`df[col].str.lower()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Rows\n",
    "\n",
    "- find rows equal to some values\n",
    "\n",
    "`temp_df = df.loc[df[level_col] == i, ]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Col turn to Row\n",
    "\n",
    "`df.melt(id_vars=['no_change_col1', 'no_change_col2'], value_vars=[col_1_row, col_2_row])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal w/ Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get 1st Value in Series\n",
    "\n",
    "- use iloc\n",
    "\n",
    "`temp_df[prv].iloc[0]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use list())dflist()\n",
    "\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set index\n",
    "\n",
    "`df.set_index('id', inplace = True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Value to One Cell\n",
    "\n",
    "`df.at[2, 'comment'] = 'good' # 2 is index`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### append another df1 to df2\n",
    "\n",
    "`df1.append(df2)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series w/ Operation\n",
    "\n",
    "### Series reshape\n",
    "\n",
    "Need to add values\n",
    "\n",
    "`a.values.reshape(x, x)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Col Type\n",
    "\n",
    "`df['col_name'] = df.astype({'col_name': 'float'}).dtypes`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series w/ Scatter Plot\n",
    "\n",
    "- Just transfer the col to datetime. Then use the matplotlib for the plotting\n",
    "\n",
    "`x = pd.to_datetime(df_short[dt_time], format='%Y-%m-%d') # if x is not time series type`\n",
    "\n",
    "`plt.scatter(x, df_short['curedCount'])`\n",
    "\n",
    "`plt.savefig('test.png')`   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd Scatter Plot\n",
    "\n",
    "- basic scatter plot\n",
    "\n",
    "    - alpha to set the color transparency\n",
    "\n",
    "`df.plot(kind = 'scatter', x = 'col1_name', y = 'col2_name', alpha = .1)`\n",
    "\n",
    "- scatter have 4 info (example is the hands-on ch2/ visualizing geographical data)\n",
    "\n",
    "    - show the population of the scatter cycle size \n",
    "\n",
    "    - show the house value w/ the color map\n",
    "\n",
    "```\n",
    "df.plot(kind = 'scatter', x = 'longitude', y = 'latitude', alpha = .4, \n",
    "    s = df['population']/ 100, label = 'population', figsize = (10, 7), \n",
    "    c = 'median_house_value', cmap = plt.get_cmap(\"jet\"), colorbar = True)\n",
    "    plt.legend()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd hist plot\n",
    "\n",
    "`df[col].hist()`\n",
    "\n",
    "parameter: \n",
    "\n",
    "- normed = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add or Minus One Day\n",
    "\n",
    "- use the pd.Timedelta(xxx)\n",
    "\n",
    "`df_short[dt_time].min() - pd.Timedelta(days = 1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal w/ Null/ NaN/ etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### NaN\n",
    "\n",
    "- check if there is NaN Value\n",
    "\n",
    "`df['col_name'].isnull().values.any()`\n",
    "\n",
    "- Show NaN Rows\n",
    "\n",
    "`nan_rows = df[df['col_name'].isnull()]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STATION</th>\n      <th>NAME</th>\n      <th>DATE</th>\n      <th>AWND</th>\n      <th>PGTM</th>\n      <th>PRCP</th>\n      <th>SNWD</th>\n      <th>TAVG</th>\n      <th>TMAX</th>\n      <th>TMIN</th>\n      <th>WDF2</th>\n      <th>WDF5</th>\n      <th>WSF2</th>\n      <th>WSF5</th>\n      <th>WT01</th>\n      <th>WT02</th>\n      <th>WT04</th>\n      <th>WT05</th>\n      <th>WT08</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>393</th>\n      <td>USW00025333</td>\n      <td>SITKA AIRPORT, AK US</td>\n      <td>2019-01-31</td>\n      <td>3.36</td>\n      <td>1846.0</td>\n      <td>0.02</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>320.0</td>\n      <td>330.0</td>\n      <td>17.0</td>\n      <td>21.9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "         STATION                  NAME        DATE  AWND    PGTM  PRCP  SNWD  \\\n393  USW00025333  SITKA AIRPORT, AK US  2019-01-31  3.36  1846.0  0.02   NaN   \n\n     TAVG  TMAX  TMIN   WDF2   WDF5  WSF2  WSF5  WT01  WT02  WT04  WT05  WT08  \n393   NaN   NaN   NaN  320.0  330.0  17.0  21.9   NaN   NaN   NaN   NaN   NaN  "
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('sitka_weather_2018_full.csv')\n",
    "\n",
    "df[df['TMAX'].isnull()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- replace that col's NaN with 0\n",
    "\n",
    "- replace that col's NaN with other col value\n",
    "\n",
    "    `df[col_w_nan].fillna(df[col_to_replace], inplace = True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('sitka_weather_2018_full.csv')\n",
    "df['TMAX'].fillna(0, inplace = True)\n",
    "df['TMAX'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- drop the NaN row with that col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('sitka_weather_2018_full.csv')\n",
    "df.dropna(subset = ['TMAX'], inplace = True)\n",
    "df['TMAX'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- drop NaN col with threshold\n",
    "\n",
    "`df1.dropna(thresh=2,axis=1)`\n",
    "\n",
    "`df1.dropna(how='all',axis=1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal w/ NaN Special Notice\n",
    "\n",
    "- Decimal Datatype\n",
    "\n",
    "    - If checked the Dataframe with `isnull` function, and the hist still shows NaN error. Check the datatype if decimal. \n",
    "\n",
    "    - Solution: convert the decimal to float, then hist is available. \n",
    "\n",
    "    ```\n",
    "    import decimal\n",
    "    \n",
    "    D = decimal.Decimal\n",
    "\n",
    "    data = [D(str(item)) for item in df['minutes_norm']]\n",
    "\n",
    "    plt.hist(np.asarray(data, dtype = 'float'), bins = 100)\n",
    "    plt.savefig('minutes_norm_hist.png')\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common w/ Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Data Basic Info\n",
    "\n",
    "- df.info() to get all the col information. \n",
    "\n",
    "- for categoary data: df.colname.value_counts() to get the rough idea about one column of data\n",
    "\n",
    "- for contnuous data: df.colname.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 405 entries, 0 to 404\nData columns (total 19 columns):\nSTATION    405 non-null object\nNAME       405 non-null object\nDATE       405 non-null object\nAWND       404 non-null float64\nPGTM       404 non-null float64\nPRCP       405 non-null float64\nSNWD       26 non-null float64\nTAVG       0 non-null float64\nTMAX       404 non-null float64\nTMIN       404 non-null float64\nWDF2       404 non-null float64\nWDF5       404 non-null float64\nWSF2       404 non-null float64\nWSF5       404 non-null float64\nWT01       25 non-null float64\nWT02       1 non-null float64\nWT04       3 non-null float64\nWT05       1 non-null float64\nWT08       1 non-null float64\ndtypes: float64(16), object(3)\nmemory usage: 60.2+ KB\n"
    },
    {
     "data": {
      "text/plain": "count    404.000000\nmean      50.594059\nstd        9.374140\nmin       21.000000\n25%       43.000000\n50%       50.000000\n75%       58.000000\nmax       73.000000\nName: TMAX, dtype: float64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('sitka_weather_2018_full.csv')\n",
    "df.info()\n",
    "df['TMAX'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}